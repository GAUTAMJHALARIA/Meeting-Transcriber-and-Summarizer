## ğŸ· Smart Meeting Assistant â€” Your AI Meeting Coâ€‘Pilot âœ¨

Turn raw meeting audio into clean transcripts, speakerâ€‘attributed conversations, and instant insights â€” ğŸ“ summaries, ğŸ§© topics, âœ… actions, and ğŸ”¦ decisions â€” all in one delightful Streamlit app.

---

### ğŸ·ï¸ Badges

![Python 3.10](https://img.shields.io/badge/python-3.10-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.33.0-ff4b4b)
![Fasterâ€‘Whisper](https://img.shields.io/badge/Faster--Whisper-0.10.0-2b90d9)
![Pyannote.audio](https://img.shields.io/badge/pyannote.audio-2.1.1-6f42c1)
![Gemini 1.5 Pro](https://img.shields.io/badge/Gemini-1.5_Pro-34a853)
![Windows](https://img.shields.io/badge/OS-Windows%2010%2B-0078d7)
![License](https://img.shields.io/badge/license-MIT-green)
![PRs welcome](https://img.shields.io/badge/PRs-welcome-brightgreen)

---

### ğŸ—‚ï¸ Table of Contents

- [ğŸ“– Overview](#overview)
- [âœ¨ Features](#features)
- [ğŸ§­ Architecture](#architecture)
- [ğŸš€ Getting Started](#getting-started)
  - [ğŸ§© Prerequisites](#prerequisites)
  - [ğŸ› ï¸ Installation](#installation)
  - [ğŸ” Environment Variables](#environment-variables)
  - [â–¶ï¸ Run](#run)
- [ğŸ® Usage](#usage)
- [ğŸ“¸ Screenshots](#screenshots)
- [âš™ï¸ Configuration](#configuration)
- [ğŸ§¯ Troubleshooting](#troubleshooting)
- [ğŸ—ºï¸ Roadmap](#roadmap)
- [ğŸ™ Acknowledgments](#acknowledgments)

---

<a id="overview"></a>
### ğŸ“– Overview

This app ingests a `.mp3` meeting recording ğŸ§, converts to highâ€‘quality mono WAV ğŸ¼, transcribes it locally with Fasterâ€‘Whisper ğŸ—£ï¸, diarizes speakers via Pyannote ğŸ§‘â€ğŸ¤â€ğŸ§‘, and then uses Google Gemini ğŸ§  to synthesize insights: summaries, topics, actions, and key decisions.

---

<a id="features"></a>
### âœ¨ Features

- **ğŸ§ Upload MP3**: Dragâ€‘andâ€‘drop in the sidebar.
- **ğŸ¼ Studioâ€‘quality conversion**: Resampled to 16 kHz, mono, 16â€‘bit PCM.
- **ğŸ—£ï¸ Accurate transcription**: Local Fasterâ€‘Whisper (`base`, CPU, int8).
- **ğŸ§‘â€ğŸ¤â€ğŸ§‘ Speaker diarization**: Segments assigned to speakers with timestamps.
- **ğŸ§  Smart insights**: Geminiâ€‘powered summary, topics, action items, decisions.
- **ğŸ“¤ Export**: Download speakerâ€‘attributed transcript as JSON.
- **âš¡ Streamlit UX**: Clean, responsive, fast.

---

<a id="architecture"></a>
### ğŸ§­ Architecture

```mermaid
graph TD
  A[Upload MP3];
  A --> B[Convert audio - pydub to 16kHz mono WAV];
  B --> C[Transcribe - Faster-Whisper];
  C -->|segments and timestamps| D[Diarize speakers - pyannote.audio];
  D --> E[Speaker attributed transcript];
  E --> F[Insights via Gemini 1_5 Pro - summary, topics, actions, decisions];
  F --> G[Streamlit UI - display and download JSON];
```

Key files ğŸ“‚:

- `app.py`: Streamlit app and UI flow
- `utils/whisper_transcribe.py`: Fasterâ€‘Whisper transcription
- `utils/diarization.py`: Pyannote diarization and segment formatting
- `utils/gemini_utils.py`: Gemini prompts for insights
- `utils/audio_utils.py`: Conversion helpers

---

<a id="getting-started"></a>
### ğŸš€ Getting Started

<a id="prerequisites"></a>
#### ğŸ§© Prerequisites

- Python 3.10 (recommended)
- Windows 10+ (others may work; instructions below focus on Windows)
- FFmpeg (required by `pydub` to read `.mp3`)
  - Install via `choco install ffmpeg` (PowerShell, with Chocolatey), or download from the FFmpeg site and add to PATH.
- Hugging Face account and token with access to `pyannote/speaker-diarization`
- Google AI Studio API key for Gemini

<a id="installation"></a>
#### ğŸ› ï¸ Installation

PowerShell (Windows) ğŸ’»:

```powershell
cd "C:\meeting summarizer"
python -m venv venv
./venv/Scripts/Activate.ps1
# Faster install (curated):
pip install --upgrade pip
pip install -r requirements2.txt
# If you need full stack:
# pip install -r requirements.txt
```

<a id="environment-variables"></a>
#### ğŸ” Environment Variables

Set the following before running:

```powershell
$env:HF_TOKEN = "<your_huggingface_token>"           # access to pyannote/speaker-diarization
$env:GEMINI_KEY = "<your_gemini_api_key>"           # Google AI Studio API key
```

Notes ğŸ’¡:

- In `utils/diarization.py`, the pipeline expects `HF_TOKEN` to be available. Export as above.
- In `utils/gemini_utils.py`, the client reads `GEMINI_KEY`.
- `app.py` configures local caches at runtime: `SPEECHBRAIN_CACHE`, `TRANSFORMERS_CACHE`, `HUGGINGFACE_HUB_CACHE`.

<a id="run"></a>
#### â–¶ï¸ Run

```powershell
streamlit run app.py
```

Open the local URL Streamlit prints (usually `http://localhost:8501`).

> Tip ğŸ’¡: The first run may download model weights â€” subsequent runs are much faster thanks to local caches.

---

<a id="usage"></a>
### ğŸ® Usage

1. ğŸ§ Upload a `.mp3` in the sidebar.
2. â³ Wait for conversion, transcription, and diarization to complete.
3. ğŸ—£ï¸ Expand the transcript to review perâ€‘speaker text and timestamps.
4. ğŸ§  Click buttons to generate:
   - ğŸ“ Summary
   - ğŸ§© Topics
   - âœ… Action Items
   - ğŸ”¦ Decisions
5. ğŸ“¤ Click â€œDownload as JSONâ€ to save the transcript.

---

<a id="screenshots"></a>
### ğŸ“¸ Screenshots

Add your own screenshots under a `docs/` folder and reference them here.

![Upload Sidebar](docs/screenshot_upload.png)
![Transcript View](docs/screenshot_transcript.png)
![Insights](docs/screenshot_insights.png)

---

<a id="configuration"></a>
### âš™ï¸ Configuration

- Change Whisper model size or device in `utils/whisper_transcribe.py`:

```python
model = WhisperModel("base", device="cpu", compute_type="int8")
```

Options: `tiny`, `base`, `small`, `medium`, `large-v3` and `device`=`cpu` or `cuda` (if available). Larger models are slower but more accurate âš–ï¸.

- If diarization is slow, consider shorter inputs or chunking. The current pipeline uses:

```python
Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=HF_TOKEN)
```

Ensure your Hugging Face token has accepted the modelâ€™s license on its model page âœ….

---

<a id="troubleshooting"></a>
### ğŸ§¯ Troubleshooting

- â— FFmpeg not found: Ensure `ffmpeg` is on PATH (`ffmpeg -version`).
- ğŸ”‘ Pyannote authorization error: Confirm `$env:HF_TOKEN` is set and you accepted access on the model page.
- ğŸ§± Torch install issues on Windows: Use the curated `requirements2.txt` first; if CUDA is not installed, keep `device="cpu"`.
- ğŸ“Š Gemini quota or auth errors: Verify `$env:GEMINI_KEY` and project quota in Google AI Studio.
- ğŸ¢ Long processing times: First run downloads models; subsequent runs use caches configured in `app.py`.

---

<a id="roadmap"></a>
### ğŸ—ºï¸ Roadmap

- ğŸŒ Multiâ€‘language transcription and translation
- âœï¸ Inline editing of transcripts and reâ€‘summarization
- ğŸ§­ Namedâ€‘entity detection (people, dates, projects)
- ğŸ“¦ Export to Markdown, DOCX, and Notion
- ğŸ“š Batch processing for multiple recordings

---

<a id="acknowledgments"></a>
### ğŸ™ Acknowledgments

- [Streamlit](https://streamlit.io/)
- [Fasterâ€‘Whisper](https://github.com/guillaumekln/faster-whisper)
- [pyannote.audio](https://github.com/pyannote/pyannote-audio)
- [Google Gemini API](https://ai.google.dev/)
- [pydub](https://github.com/jiaaro/pydub)

â€” Made with â¤ï¸ to make your meetings productive again. ğŸ·


